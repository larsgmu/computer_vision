{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_colorization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTpPhHm-xBOS"
      },
      "source": [
        "import keras\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Layer\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import TensorBoard \n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import RepeatVector, Permute\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYJtUKLvAHbc",
        "outputId": "87cea161-01e9-41f6-e7c8-c2208a7fc9de"
      },
      "source": [
        "# Download images form github repo\n",
        "\n",
        "!wget https://github.com/emilwallner/Coloring-greyscale-images/archive/master.tar.gz\n",
        "!tar xvzf master.tar.gz\n",
        "\n",
        "X = []\n",
        "for filename in os.listdir('Coloring-greyscale-images-master/Full-version/Train/'):\n",
        "    X.append(img_to_array(load_img('Coloring-greyscale-images-master/Full-version/Train/'+filename)))\n",
        "X = np.array(X, dtype=float)\n",
        "Xtrain = 1.0/255*X"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-04 12:55:34--  https://github.com/emilwallner/Coloring-greyscale-images/archive/master.tar.gz\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/emilwallner/Coloring-greyscale-images/tar.gz/master [following]\n",
            "--2021-06-04 12:55:34--  https://codeload.github.com/emilwallner/Coloring-greyscale-images/tar.gz/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.255.121\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.255.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘master.tar.gz.9’\n",
            "\n",
            "master.tar.gz.9         [  <=>               ]   5.76M  22.0MB/s    in 0.3s    \n",
            "\n",
            "2021-06-04 12:55:34 (22.0 MB/s) - ‘master.tar.gz.9’ saved [6043320]\n",
            "\n",
            "Coloring-greyscale-images-master/\n",
            "Coloring-greyscale-images-master/.gitignore\n",
            "Coloring-greyscale-images-master/Alpha-version/\n",
            "Coloring-greyscale-images-master/Alpha-version/alpha_version_notebook.ipynb\n",
            "Coloring-greyscale-images-master/Alpha-version/man.jpg\n",
            "Coloring-greyscale-images-master/Alpha-version/swim.jpg\n",
            "Coloring-greyscale-images-master/Alpha-version/woman.jpg\n",
            "Coloring-greyscale-images-master/Beta-version/\n",
            "Coloring-greyscale-images-master/Beta-version/alpha_version_test_generalization.ipynb\n",
            "Coloring-greyscale-images-master/Beta-version/beta_version.ipynb\n",
            "Coloring-greyscale-images-master/Beta-version/result/\n",
            "Coloring-greyscale-images-master/Beta-version/result/img_0.png\n",
            "Coloring-greyscale-images-master/Beta-version/result/img_1.png\n",
            "Coloring-greyscale-images-master/Beta-version/result/img_2.png\n",
            "Coloring-greyscale-images-master/Beta-version/result/img_3.png\n",
            "Coloring-greyscale-images-master/Beta-version/result/img_4.png\n",
            "Coloring-greyscale-images-master/Beta-version/result/img_5.png\n",
            "Coloring-greyscale-images-master/Beta-version/result/img_6.png\n",
            "Coloring-greyscale-images-master/Beta-version/result/img_7.png\n",
            "Coloring-greyscale-images-master/Full-version/\n",
            "Coloring-greyscale-images-master/Full-version/Test/\n",
            "Coloring-greyscale-images-master/Full-version/Test/0fAtAB.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Test/0yTHvf.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Test/1QejlL 4.11.06 PM.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Test/3YFtxe.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Test/4r3yxj.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Test/6v14hm.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Test/7Vizcm.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Test/9KfZez.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Train/\n",
            "Coloring-greyscale-images-master/Full-version/Train/0qADtP.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Train/11Se02.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Train/1PFDZe.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Train/27gIpN.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Train/29Pkqp.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Train/30gdlQ.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Train/8X0jDX.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Train/8ntGqA.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Train/8oZO2i.jpg\n",
            "Coloring-greyscale-images-master/Full-version/Train/9KkoOf.jpg\n",
            "Coloring-greyscale-images-master/Full-version/full_version.ipynb\n",
            "Coloring-greyscale-images-master/Full-version/result/\n",
            "Coloring-greyscale-images-master/Full-version/result/img_0.png\n",
            "Coloring-greyscale-images-master/GAN-version/\n",
            "Coloring-greyscale-images-master/GAN-version/Test/\n",
            "Coloring-greyscale-images-master/GAN-version/Test/0fAtAB.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Test/0yTHvf.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Test/1QejlL 4.11.06 PM.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Test/3YFtxe.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Test/4r3yxj.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Test/6v14hm.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Test/7Vizcm.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Test/9KfZez.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Train/\n",
            "Coloring-greyscale-images-master/GAN-version/Train/0qADtP.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Train/11Se02.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Train/1PFDZe.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Train/27gIpN.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Train/29Pkqp.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Train/30gdlQ.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Train/8X0jDX.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Train/8ntGqA.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Train/8oZO2i.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/Train/9KkoOf.jpg\n",
            "Coloring-greyscale-images-master/GAN-version/colorize_base.py\n",
            "Coloring-greyscale-images-master/GAN-version/lib/\n",
            "Coloring-greyscale-images-master/GAN-version/lib/data_utils.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/\n",
            "Coloring-greyscale-images-master/GAN-version/models/core_generator.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/discriminator_full.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/discriminator_low.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/discriminator_medium.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/pix2pixHD/\n",
            "Coloring-greyscale-images-master/GAN-version/models/pix2pixHD/core_generator_load.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/pix2pixHD/enhancer.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/pix2pixHD/load_trained_models.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/pix2pixHD/load_weights.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/utils/\n",
            "Coloring-greyscale-images-master/GAN-version/models/utils/AdamAccumulate.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/utils/attention.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/utils/calc_output_and_feature_size.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/utils/conv2d_r.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/utils/instance_normalization.py\n",
            "Coloring-greyscale-images-master/GAN-version/models/utils/sn.py\n",
            "Coloring-greyscale-images-master/LICENSE\n",
            "Coloring-greyscale-images-master/README.md\n",
            "Coloring-greyscale-images-master/README_images/\n",
            "Coloring-greyscale-images-master/README_images/alpha.png\n",
            "Coloring-greyscale-images-master/README_images/beta.png\n",
            "Coloring-greyscale-images-master/README_images/coloring-black-and-white-images-with-neural-networks.svg\n",
            "Coloring-greyscale-images-master/README_images/full.png\n",
            "Coloring-greyscale-images-master/README_images/fusion_layer.png\n",
            "Coloring-greyscale-images-master/README_images/gan.png\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/Copy_50_files_to_another_folder.ipynb\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/Create_random_cropped_images_from_large_images.ipynb\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/README.md\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/Remove_Black_and_White_Photos.ipynb\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/Remove_clipart_images_from_dataset.ipynb\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/Remove_dups.ipynb\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/Remove_too_small_images_from_dataset.ipynb\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/multi_crop_images.py\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/multi_resize.py\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/pixabay/\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/pixabay/pixabay_main_custom.py\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/pixabay/utils.py\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/yahoo_fcc100m_dataset/\n",
            "Coloring-greyscale-images-master/download_and_clean_data_scripts/yahoo_fcc100m_dataset/parse100m.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L35oCwRmAC6N",
        "outputId": "4af927a0-a0d8-4959-853c-e36d9579a8a4"
      },
      "source": [
        "# Create encode, fusion layer and decocer and instantiate model\n",
        "inception = InceptionResNetV2(weights='imagenet', include_top=True)\n",
        "embed_input = Input(shape=(1000,))\n",
        "\n",
        "encoder_input = Input(shape=(256, 256, 1,))\n",
        "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "\n",
        "fusion_output = RepeatVector(32 * 32)(embed_input) \n",
        "fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
        "fusion_output = tf.keras.layers.Concatenate(axis=3)([encoder_output, fusion_output])\n",
        "fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output)\n",
        "\n",
        "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "225214464/225209952 [==============================] - 3s 0us/step\n",
            "225222656/225209952 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzk7eP5yFtUy"
      },
      "source": [
        "# Inception predictions and data generator\n",
        "def create_inception_embedding(grayscaled_rgb):\n",
        "    grayscaled_rgb_resized = []\n",
        "    for i in grayscaled_rgb:\n",
        "      i = resize(i, (299, 299, 3), mode='constant')\n",
        "      grayscaled_rgb_resized.append(i)\n",
        "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
        "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
        "    embed = inception.predict(grayscaled_rgb_resized)\n",
        "    return embed\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.4,\n",
        "        zoom_range=0.4,\n",
        "        rotation_range=40,\n",
        "        horizontal_flip=True)\n",
        "        \n",
        "batch_size = 20\n",
        "\n",
        "def image_a_b_gen(batch_size):\n",
        "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
        "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
        "        embed = create_inception_embedding(grayscaled_rgb)\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        yield ([X_batch, embed], Y_batch)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKGSVHQqFw7I",
        "outputId": "f635e8f8-ef7a-42f3-85a4-a68d017bbfeb"
      },
      "source": [
        "# Compile and Train model\n",
        "tensorboard = TensorBoard(log_dir=\"/output\")\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(image_a_b_gen(batch_size), callbacks=[tensorboard], epochs=50, steps_per_epoch=5)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 15s 637ms/step - loss: 0.1315\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 3s 544ms/step - loss: 0.0079\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 3s 578ms/step - loss: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 3s 577ms/step - loss: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 3s 585ms/step - loss: 0.0057\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 3s 570ms/step - loss: 0.0061\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 3s 580ms/step - loss: 0.0059\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 3s 552ms/step - loss: 0.0058\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 3s 562ms/step - loss: 0.0058\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 3s 580ms/step - loss: 0.0058\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 3s 578ms/step - loss: 0.0055\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 3s 578ms/step - loss: 0.0056\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 3s 588ms/step - loss: 0.0057\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 3s 576ms/step - loss: 0.0054\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 3s 575ms/step - loss: 0.0055\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 3s 553ms/step - loss: 0.0057\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 3s 550ms/step - loss: 0.0054\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 3s 554ms/step - loss: 0.0053\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 3s 570ms/step - loss: 0.0055\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 3s 588ms/step - loss: 0.0052\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 3s 559ms/step - loss: 0.0057\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 3s 565ms/step - loss: 0.0054\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 3s 553ms/step - loss: 0.0057\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 3s 554ms/step - loss: 0.0055\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 3s 586ms/step - loss: 0.0056\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 3s 580ms/step - loss: 0.0054\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 3s 550ms/step - loss: 0.0054\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 3s 565ms/step - loss: 0.0054\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 3s 556ms/step - loss: 0.0053\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 3s 593ms/step - loss: 0.0053\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 3s 578ms/step - loss: 0.0058\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 3s 559ms/step - loss: 0.0055\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 3s 578ms/step - loss: 0.0054\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 3s 579ms/step - loss: 0.0054\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 3s 569ms/step - loss: 0.0052\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 3s 573ms/step - loss: 0.0051\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 3s 586ms/step - loss: 0.0053\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 3s 556ms/step - loss: 0.0051\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 0.0051\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 3s 566ms/step - loss: 0.0049\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 3s 580ms/step - loss: 0.0050\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 3s 573ms/step - loss: 0.0051\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 3s 578ms/step - loss: 0.0047\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 3s 565ms/step - loss: 0.0048\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 3s 563ms/step - loss: 0.0050\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 3s 569ms/step - loss: 0.0051\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 3s 575ms/step - loss: 0.0049\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 3s 567ms/step - loss: 0.0048\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 3s 591ms/step - loss: 0.0048\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 3s 572ms/step - loss: 0.0047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2145439610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eOYQqGcC41D",
        "outputId": "a7f7b2fa-cd8e-4bd6-b1b0-96dc87a59aac"
      },
      "source": [
        "# Test results and colorize output\n",
        "color_me = []\n",
        "for filename in os.listdir('Coloring-greyscale-images-master/Full-version/Test/'):\n",
        "    color_me.append(img_to_array(load_img('Coloring-greyscale-images-master/Full-version/Test/'+filename)))\n",
        "color_me = np.array(color_me, dtype=float)\n",
        "color_me = 1.0/255*color_me\n",
        "color_me = gray2rgb(rgb2gray(color_me))\n",
        "color_me_embed = create_inception_embedding(color_me)\n",
        "color_me = rgb2lab(color_me)[:,:,:,0]\n",
        "color_me = color_me.reshape(color_me.shape+(1,))\n",
        "\n",
        "output = model.predict([color_me, color_me_embed])\n",
        "output = output * 128\n",
        "\n",
        "for i in range(len(output)):\n",
        "    cur = np.zeros((256, 256, 3))\n",
        "    cur[:,:,0] = color_me[i][:,:,0]\n",
        "    cur[:,:,1:] = output[i]\n",
        "    imsave(\"Result/img_\"+str(i)+\".png\", lab2rgb(cur))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}